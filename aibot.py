import json
import os
import logging
import time
from datetime import date
from textwrap import dedent

from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler
import openai
from dotenv import load_dotenv

# setup
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)
load_dotenv()
app = App()
my_user_id = app.client.auth_test().data["user_id"]
openai.api_key = os.getenv('OPENAI_API_KEY')
OPENAI_TEXT_PARAMS = {
    'model': "text-davinci-003",
    'temperature': 0.7,
    'max_tokens': 250,
    'top_p': 1,
    'frequency_penalty': 0,
    'presence_penalty': 0,
}
OPENAI_IMG_PARAMS = {
    "n": 1,
    "size": "1024x1024",
}
cached_user_info = {}
cached_team_fields = {}

### helpers ###

def get_text(prompt, **extra_params):
    response = openai.Completion.create(prompt=prompt, **{**OPENAI_TEXT_PARAMS, **extra_params})
    logger.debug(f"OpenAI response: {response}")
    return response.choices[0].text.strip().strip('"')

def get_image(prompt, **extra_params):
    response = openai.Image.create(prompt=prompt, **{**OPENAI_IMG_PARAMS, **extra_params})
    logger.debug(f"OpenAI response: {response}")
    return response['data'][0]['url']

def block_text(text):
    """Return simple text string formatted for Slack block."""
    return {
        "type": "plain_text",
        "text": text,
    }

def id_to_user_info(user_id):
    if user_id not in cached_user_info:
        if not cached_team_fields:
            team_profile = app.client.team_profile_get()
            cached_team_fields.update({f["id"]: f["label"] for f in team_profile["profile"]["fields"]})
        user_profile = app.client.users_profile_get(user=user_id)["profile"]
        user_info = {k: user_profile.get(k) for k in ['real_name', 'display_name', 'first_name', 'last_name', 'title', 'status_text', 'status_emoji', 'pronouns']}
        for label_id, label in cached_team_fields.items():
            user_info[label] = user_profile["fields"].get(label_id, {'value': ''})['value']
        user_info = {k: v for k, v in user_info.items() if v}
        cached_user_info[user_id] = user_info
    return cached_user_info[user_id]

def readable_timedelta(seconds):
    # via https://codereview.stackexchange.com/a/245215
    data = {}
    data['days'], remaining = divmod(seconds, 86_400)
    data['hours'], remaining = divmod(remaining, 3_600)
    data['minutes'], data['seconds'] = divmod(remaining, 60)

    time_parts = [f'{round(value)} {name}' for name, value in data.items() if value > 0]
    if time_parts:
        return ' '.join(time_parts)
    else:
        return 'less than 1 second'


### views ###

@app.command("/ai")
def ai(ack, respond, command):
    logger.debug(command)
    ack()

    response_type = "ephemeral"
    img_prompt = False
    prompt = command['text']

    # help command
    if prompt == "help":
        respond(dedent(f"""
            Available commands:
            * `/ai <prompt>`: Show the {OPENAI_TEXT_PARAMS['model']} model's response to `<prompt>`. Visible only to you.
            * `/ai img <prompt>`: Show the Dall-E image generated by `<prompt>`. Visible only to you.
            * `/ai say <prompt>` or * `/ai say img <prompt>`: immediately post the result to the channel.
        """))
        return

    # parse 'say' and 'img' from prompt
    if prompt.split(maxsplit=1)[0] == "say":
        response_type = "in_channel"
        prompt = prompt.split(maxsplit=1)[1]
    if prompt.split(maxsplit=1)[0] == "img":
        img_prompt = True
        prompt = prompt.split(maxsplit=1)[1]

    # generate image or text response
    formatted_prompt = f"{command['user_name']} asked: /ai {command['text']}"
    if img_prompt:
        response = get_image(prompt)
        blocks = [{
            "type": "image",
            "title": block_text(formatted_prompt),
            "image_url": response,
            "alt_text": f"Dall-E image generated for the prompt {prompt}",
        }]
    else:
        response = get_text(prompt)
        blocks = [
            {"type": "context", "elements": [block_text(formatted_prompt)]},
		    {"type": "section", "text": block_text(response)},
        ]

    # show "Post publicly" button if message not already public, and we're not in a DM where we can't post
    if response_type == "ephemeral" and command["channel_name"] != "directmessage":
        blocks.append({
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": block_text("Post publicly"),
                    "value": json.dumps({"text": formatted_prompt, "blocks": blocks}),
                    "action_id": "public_repost"
                }
            ]
        })

    respond(formatted_prompt, response_type=response_type, blocks=blocks)

@app.action("public_repost")
def public_repost(ack, payload, respond, say):
    """Handle 'Post publicly' button."""
    ack()
    to_repost = json.loads(payload['value'])
    say(to_repost["text"], response_type="in_channel", blocks=to_repost["blocks"])
    respond(text='', replace_original=True, delete_original=True)

@app.event("message")
def handle_dm(ack, payload, logger, say):
    """Handle conversations with the app itself."""
    ack()

    users_in_convo = {id: id_to_user_info(id) for id in [payload['user'], my_user_id]}
    my_user_info = users_in_convo[my_user_id]

    latest_message = payload["text"]
    if latest_message == "help":
        say(dedent(f"""
            I'm {my_user_info['real_name']}, a friendly, helpful AI bot. You can just talk to me, or I'll do special things if you send one of these messages:
            * `reset`: I'll ignore anything we said before this message.
            * `prompt`: I'll show the entire prompt I would have used to generate a response.
        """))
        return

    # fetch previous slack messages in conversation, and turn into prompts like "<User Name | 3 minutes ago>: message"
    formatted_messages = []
    if latest_message != "reset":
        messages = app.client.conversations_history(channel=payload["channel"])
        messages = messages.data["messages"]
        for message in messages:
            if message['text'] == "reset":
                break
            user_info = users_in_convo[message["user"]] = id_to_user_info(message['user'])
            user_name = user_info['real_name']
            readable_age = readable_timedelta(time.time() - int(float(message["ts"])))
            formatted_messages.append(f"<{user_name} | {readable_age} ago>: {message['text']}")

    # list of stop tokens to stop it from generating replies to itself
    stop_tokens = [f"<{user_info['real_name']} |" for user_info in users_in_convo.values()]

    # list of user bios
    bios = "* " + "\n*".join(
        user_info["real_name"] + ": " +
        " ".join(f"{k} is {v}." for k, v in user_info.items() if k != "real_name")
        for user_info in users_in_convo.values()
    )

    # list of messages
    max_prompt_length = 1000  # characters
    history_text = ""
    for message in formatted_messages:
        history_text = f"\n{message}{history_text}"
        if len(history_text) > max_prompt_length:
            break

    # fetch OpenAI response
    prompt = f"""
This is a conversation with {my_user_info['real_name']}, a friendly, helpful AI bot.
Today is {date.today().strftime("%A, %B %-d, %Y.")}

These are the people in the conversation:
{bios}
{history_text}
<{my_user_info['real_name']} | now>:
    """.strip()
    if latest_message == "prompt":
        response = f"```{prompt.replace('```', '')}```"
    else:
        response = get_text(prompt, stop=list(stop_tokens))

    say(response, response_type="in_channel")

if __name__ == "__main__":
    handler = SocketModeHandler(app)
    handler.start()